{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297c6d2f-d003-4155-b344-1bd161ec06c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Load the training data\u001b[39;00m\n\u001b[0;32m     11\u001b[0m train_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIntern13\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mqtm\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mwether\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the training data\n",
    "train_data = pd.read_csv(r'C:\\Users\\Intern13\\Desktop\\project\\qtm\\dataset\\wether\\train.csv')\n",
    "\n",
    "# Convert 'time' column to datetime\n",
    "train_data['time'] = pd.to_datetime(train_data['time'], format='%d-%m-%Y')\n",
    "\n",
    "# Sort the data by time\n",
    "train_data = train_data.sort_values('time')\n",
    "\n",
    "# Fill null values using interpolation\n",
    "train_data = train_data.interpolate(method='linear').ffill().bfill()\n",
    "\n",
    "# Convert all columns (except 'time') to numeric type\n",
    "for col in train_data.columns:\n",
    "    if col != 'time':\n",
    "        train_data[col] = pd.to_numeric(train_data[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Extract additional time-based features\n",
    "train_data['day_of_year'] = train_data['time'].dt.dayofyear\n",
    "train_data['month'] = train_data['time'].dt.month\n",
    "train_data['day_of_week'] = train_data['time'].dt.dayofweek\n",
    "train_data['is_weekend'] = train_data['day_of_week'] >= 5\n",
    "train_data['quarter'] = train_data['time'].dt.quarter\n",
    "\n",
    "# Prepare features (X) and target variable (y)\n",
    "features = ['tmin', 'tmax', 'prcp', 'day_of_year', 'month', 'day_of_week', 'is_weekend', 'quarter']\n",
    "X = train_data[features]\n",
    "y = train_data['tavg']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data for cross-validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform hyperparameter tuning for XGBRegressor\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Generate prediction dates\n",
    "prediction_start_date = pd.to_datetime(\"01-01-2018\", format='%d-%m-%Y')\n",
    "num_months = 54\n",
    "prediction_dates = pd.date_range(start=prediction_start_date, periods=num_months*30, freq='D')\n",
    "\n",
    "# Function to create features for a given date\n",
    "def create_features(date, historical_data):\n",
    "    return pd.DataFrame({\n",
    "        'tmin': [historical_data[historical_data['time'] < date]['tmin'].mean()],\n",
    "        'tmax': [historical_data[historical_data['time'] < date]['tmax'].mean()],\n",
    "        'prcp': [historical_data[historical_data['time'] < date]['prcp'].mean()],\n",
    "        'day_of_year': [date.dayofyear],\n",
    "        'month': [date.month],\n",
    "        'day_of_week': [date.dayofweek],\n",
    "        'is_weekend': [date.dayofweek >= 5],\n",
    "        'quarter': [date.quarter]\n",
    "    })\n",
    "\n",
    "# Make predictions\n",
    "predictions = []\n",
    "for date in prediction_dates:\n",
    "    features = create_features(date, train_data)\n",
    "    features_scaled = scaler.transform(features)\n",
    "    pred = model.predict(features_scaled)\n",
    "    predictions.append(pred[0])\n",
    "\n",
    "# Create a DataFrame with predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'time': prediction_dates,\n",
    "    'predicted_tavg': predictions\n",
    "})\n",
    "\n",
    "# Load the comparison data\n",
    "comparison_data = pd.read_csv(r'C:\\Users\\Intern13\\Desktop\\project\\qtm\\dataset\\wether\\test.csv')\n",
    "comparison_data['time'] = pd.to_datetime(comparison_data['time'], format='%d-%m-%Y')\n",
    "\n",
    "# Merge predictions with actual data\n",
    "combined_df = pd.merge(predictions_df, comparison_data[['time', 'tavg']], on='time', how='left')\n",
    "\n",
    "# Calculate error metrics for the period where we have actual data\n",
    "mask = combined_df['tavg'].notnull()\n",
    "mse = mean_squared_error(combined_df.loc[mask, 'tavg'], combined_df.loc[mask, 'predicted_tavg'])\n",
    "r2 = r2_score(combined_df.loc[mask, 'tavg'], combined_df.loc[mask, 'predicted_tavg'])\n",
    "mae = mean_absolute_error(combined_df.loc[mask, 'tavg'], combined_df.loc[mask, 'predicted_tavg'])\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# Plot predictions vs actual values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(combined_df['time'], combined_df['predicted_tavg'], label='Predicted')\n",
    "plt.plot(combined_df['time'], combined_df['tavg'], label='Actual')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Temperature')\n",
    "plt.title('Predicted vs Actual Average Temperature')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the predictions\n",
    "print(combined_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "output_file = 'C:/Users/Intern13/Desktop/project/qtm/dataset/wether/answer.csv'\n",
    "\n",
    "try:\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    \n",
    "    # Save the file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Results successfully saved to {output_file}\")\n",
    "except PermissionError:\n",
    "    print(f\"Permission denied: Unable to save to {output_file}. Please check your write permissions for this location.\")\n",
    "except IOError as e:\n",
    "    print(f\"An error occurred while saving the file: {e}\")\n",
    "    print(\"Please check if the path is correct and you have the necessary permissions.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "    print(\"Please check your file path and permissions.\")\n",
    "\n",
    "# Print the first few rows of the dataframe to verify the data\n",
    "print(\"\\nFirst few rows of the combined dataframe:\")\n",
    "print(combined_df.head())\n",
    "\n",
    "# Print the total number of rows in the dataframe\n",
    "print(f\"\\nTotal number of rows in the dataframe: {len(combined_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee749ec1-2c5a-40e9-a5ea-6b5fbfdd8313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
